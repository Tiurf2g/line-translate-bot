from fastapi import FastAPI, Request
import requests, os, json
from openai import OpenAI

app = FastAPI()

LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
LINE_REPLY_API = "https://api.line.me/v2/bot/message/reply"

KV_URL = os.getenv("KV_REST_API_URL")
KV_TOKEN = os.getenv("KV_REST_API_TOKEN")

SETTINGS_KEY = "translator_settings"
CACHE_KEY = "translator_cache"

client = OpenAI(api_key=OPENAI_API_KEY)

# ================================
# Upstash REST API
# ================================
def kv_get(key: str, default=None):
    try:
        res = requests.get(
            f"{KV_URL}/get/{key}",
            headers={"Authorization": f"Bearer {KV_TOKEN}"},
            timeout=5
        )
        raw = res.json().get("result")

        if not raw:
            return default

        if isinstance(raw, dict):
            raw = raw.get("data")

        if not raw:
            return default

        data = json.loads(raw)
        return data if isinstance(data, dict) else default
    except:
        return default


def kv_set(key: str, value):
    try:
        requests.post(
            f"{KV_URL}/set/{key}",
            headers={
                "Authorization": f"Bearer {KV_TOKEN}",
                "Content-Type": "application/json"
            },
            json={"value": json.dumps(value)},
            timeout=5
        )
    except:
        pass


# =============== Settings/Cache ===============
def load_settings():
    data = kv_get(SETTINGS_KEY, {})
    return data if isinstance(data, dict) else {}


def save_settings(data):
    kv_set(SETTINGS_KEY, data)


def load_cache():
    data = kv_get(CACHE_KEY, {})
    return data if isinstance(data, dict) else {}


def save_cache(data):
    kv_set(CACHE_KEY, data)


# =============== èªè¨€æ­£è¦åŒ–ï¼ˆå¼·åŒ–ç‰ˆï¼‰ ===============
LANG_ALIASES = {
    "ä¸­æ–‡": ["ä¸­æ–‡", "ç¹ä¸­", "ç¹é«”ä¸­æ–‡", "zh", "chinese", "cn"],
    "è‹±æ–‡": ["è‹±æ–‡", "è‹±", "en", "english"],
    "è¶Šå—æ–‡": ["è¶Šå—æ–‡", "è¶Šæ–‡", "vi", "vietnamese"],
    "æ—¥æ–‡": ["æ—¥æ–‡", "jp", "ja", "japanese"],
    "éŸ“æ–‡": ["éŸ“æ–‡", "kr", "ko", "korean"],
    "å°å°¼æ–‡": ["å°å°¼æ–‡", "id", "indonesian", "bahasa"],
    "æ³°æ–‡": ["æ³°æ–‡", "th", "thai"],
    "è¥¿ç­ç‰™æ–‡": ["è¥¿ç­ç‰™æ–‡", "è¥¿æ–‡", "es", "spanish"],
    "å¾·æ–‡": ["å¾·æ–‡", "de", "german"],
}


def normalize_lang(name: str) -> str:
    if not name:
        return "ä¸­æ–‡"

    n = name.strip().lower().replace(" ", "")

    for std, alts in LANG_ALIASES.items():
        # æ¨™æº–èªæœ¬èº«
        if n == std.lower():
            return std

        # åŒç¾©è©
        for a in alts:
            if n == a.lower().replace(" ", ""):
                return std

    return name.strip()


# =============== èªè¨€åµæ¸¬ï¼ˆä½¿ç”¨ gpt-4oï¼‰ ===============
def detect_language(text: str, cache):
    cache_key = f"detect::{text}"
    if cache_key in cache:
        return cache[cache_key]

    prompt = (
        "åµæ¸¬é€™å¥è©±çš„èªè¨€ï¼Œåªå›ç­”ï¼šä¸­æ–‡ã€è‹±æ–‡ã€è¶Šå—æ–‡ã€æ—¥æ–‡ã€éŸ“æ–‡ã€å°å°¼æ–‡ã€æ³°æ–‡ã€è¥¿ç­ç‰™æ–‡ã€å¾·æ–‡\n\n"
        f"{text}"
    )

    try:
        res = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯èªè¨€è­˜åˆ¥å°ˆå®¶ã€‚å›ç­”è¦éå¸¸ç²¾æº–ã€‚"},
                {"role": "user", "content": prompt},
            ],
            temperature=0
        )
        lang = normalize_lang(res.choices[0].message.content.strip())
    except:
        lang = "è‹±æ–‡"

    cache[cache_key] = lang
    save_cache(cache)
    return lang


# =============== ç¿»è­¯åŠŸèƒ½ï¼ˆgpt-4o å…¨å¼·åŒ–ï¼‰ ===============
def translate_text(text, source_lang, target_lang, cache, tone="normal"):
    cache_key = f"trans::{source_lang}->{target_lang}::{tone}::{text}"
    if cache_key in cache:
        return cache[cache_key]

    tone_map = {
        "normal": "è‡ªç„¶ã€é †å£ã€ç¦®è²Œã€‚",
        "formal": "æ­£å¼ã€åš´è¬¹ã€ç²¾æº–ã€‚",
        "casual": "æ—¥å¸¸èŠå¤©èªæ°£ã€‚",
    }

    style = "ç¹é«”ä¸­æ–‡ï¼ˆå°ç£ç”¨èªï¼‰" if target_lang == "ä¸­æ–‡" else target_lang

    prompt = (
        f"è«‹å°‡ä»¥ä¸‹å…§å®¹ç¿»è­¯æˆ {style}ï¼Œèªæ°£ä½¿ç”¨ï¼š{tone_map[tone]}\n"
        f"è‹¥å…§å®¹æœ¬èº«å·²æ˜¯ç›®æ¨™èªè¨€è«‹ç›´æ¥å›å‚³åŸæ–‡ã€‚\n\n{text}"
    )

    try:
        res = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­ç¿»è­¯å“¡ï¼Œç¿»è­¯è‡ªç„¶ä¸æ­»æ¿ã€‚"},
                {"role": "user", "content": prompt},
            ],
            temperature=0.3
        )
        result = res.choices[0].message.content.strip()
    except:
        result = text

    # è£œå¼·ç°¡é«” â†’ ç¹é«”
    if target_lang == "ä¸­æ–‡":
        trad = {
            "è¿™": "é€™","ç€": "è‘—","ä¹ˆ": "éº¼","ä¸º": "ç‚º","äº": "æ–¼",
            "è§‰": "è¦º","å¬": "è½","å…³": "é—œ","å¤´": "é ­","ç”µ": "é›»",
        }
        for k, v in trad.items():
            result = result.replace(k, v)

    cache[cache_key] = result
    save_cache(cache)
    return result


# =============== LINE å›è¦† ===============
def line_reply(reply_token, text):
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}",
    }
    body = {
        "replyToken": reply_token,
        "messages": [{"type": "text", "text": text[:4900]}],
    }
    requests.post(LINE_REPLY_API, headers=headers, json=body)


# =============== key ä¾†æº ===============
def get_source_key(ev):
    src = ev.get("source", {})
    stype = src.get("type")

    if stype == "user":
        return f"user:{src.get('userId')}"
    if stype == "group":
        return f"group:{src.get('groupId')}"
    if stype == "room":
        return f"room:{src.get('roomId')}"
    return "unknown"


# =============== Smart æ¨¡å¼é‚è¼¯ ===============
def smart_target(detected_lang, cfg):
    if not cfg.get("smart"):
        return cfg["target"]

    # ä¸»äººéœ€æ±‚ï¼šä¸­ â†” è¶Š è‡ªå‹•äº’ç¿»
    if detected_lang == "ä¸­æ–‡":
        return "è¶Šå—æ–‡"
    if detected_lang == "è¶Šå—æ–‡":
        return "ä¸­æ–‡"

    # å…¶ä»–èªè¨€ â†’ ä¸­æ–‡
    return "ä¸­æ–‡"


# =============== webhook ä¸»ç¨‹å¼ï¼ˆæœ€çµ‚ç‰ˆï¼‰ ===============
@app.post("/api/webhook")
async def webhook(req: Request):
    try:
        body = await req.json()
    except:
        return {"status": "ok"}

    events = body.get("events", [])
    settings = load_settings()
    cache = load_cache()

    for ev in events:
        if ev.get("type") != "message":
            continue

        msg = ev.get("message", {})
        if msg.get("type") != "text":
            continue

        user_msg = msg.get("text").strip()
        msg_lower = user_msg.lower()
        reply_token = ev.get("replyToken")
        key = get_source_key(ev)

        # åˆå§‹åŒ–è¨­å®š
        if key not in settings:
            settings[key] = {
                "enabled": True,
                "target": "ä¸­æ–‡",
                "tone": "normal",
                "smart": False,
            }

        cfg = settings[key]

        # ===== æŒ‡ä»¤è™•ç† =====
        if msg_lower == "/status":
            line_reply(
                reply_token,
                f"ğŸ”§ ç‹€æ…‹ï¼š{'ON' if cfg['enabled'] else 'OFF'}\n"
                f"ğŸŒ ç›®æ¨™èªè¨€ï¼š{cfg['target']}\n"
                f"ğŸ™ï¸ èªæ°£ï¼š{cfg['tone']}\n"
                f"ğŸ¤– Smartï¼š{'ON' if cfg['smart'] else 'OFF'}"
            )
            continue

        if msg_lower.startswith("/set "):
            lang_raw = msg_lower.replace("/set", "").strip()
            lang = normalize_lang(lang_raw)
            cfg["target"] = lang
            cfg["enabled"] = True
            save_settings(settings)
            line_reply(reply_token, f"âœ… å·²è¨­å®šï¼Œä¹‹å¾Œç¿»è­¯å°‡è½‰æˆï¼š{lang}")
            continue

        if msg_lower == "/smart on":
            cfg["smart"] = True
            save_settings(settings)
            line_reply(reply_token, "ğŸ¤– Smart æ¨¡å¼ï¼šONï¼ˆä¸­è¶Šäº’ç¿»ï¼‰")
            continue

        if msg_lower == "/smart off":
            cfg["smart"] = False
            save_settings(settings)
            line_reply(reply_token, "ğŸ§© Smart æ¨¡å¼ï¼šOFF")
            continue

        if msg_lower == "/on":
            cfg["enabled"] = True
            save_settings(settings)
            line_reply(reply_token, "â–¶ï¸ è‡ªå‹•ç¿»è­¯ï¼šON")
            continue

        if msg_lower == "/off":
            cfg["enabled"] = False
            save_settings(settings)
            line_reply(reply_token, "â¸ï¸ è‡ªå‹•ç¿»è­¯ï¼šOFF")
            continue

        # ============================
        # è‡ªå‹•ç¿»è­¯ï¼ˆå®Œæ•´å‡ç´šç‰ˆï¼‰
        # ============================
        if cfg["enabled"]:
            detected = detect_language(user_msg, cache)
            target = smart_target(detected, cfg)

            if detected != target:
                translated = translate_text(
                    user_msg, detected, target, cache, tone=cfg["tone"]
                )
                line_reply(reply_token, translated)

    return {"status": "ok"}
