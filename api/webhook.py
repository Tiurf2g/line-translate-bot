from fastapi import FastAPI, Request
import requests, os, json
from openai import OpenAI

app = FastAPI()

LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
LINE_REPLY_API = "https://api.line.me/v2/bot/message/reply"

KV_URL = os.getenv("KV_REST_API_URL")
KV_TOKEN = os.getenv("KV_REST_API_TOKEN")

SETTINGS_KEY = "translator_settings"
CACHE_KEY = "translator_cache"

client = OpenAI(api_key=OPENAI_API_KEY)


# ================================
# Upstash REST APIï¼ˆæ­£ç¢ºæ ¼å¼ï¼‰
# ================================
def kv_get(key: str, default=None):
    try:
        res = requests.get(
            f"{KV_URL}/get/{key}",
            headers={"Authorization": f"Bearer {KV_TOKEN}"},
            timeout=5
        )

        raw = res.json().get("result")

        if not raw:
            return default

        # Upstash æœ‰å…©ç¨®æ ¼å¼ï¼šå­—ä¸² or dict
        # 1) {"result": "...."}  â† èˆŠæ ¼å¼
        # 2) {"result": {"data": "...", "error": null}} â† æ–°æ ¼å¼
        if isinstance(raw, dict):
            raw = raw.get("data")

        if not raw:
            return default

        return json.loads(raw)

    except Exception:
        return default


def kv_set(key: str, value):
    try:
        requests.post(
            f"{KV_URL}/set/{key}",
            headers={
                "Authorization": f"Bearer {KV_TOKEN}",
                "Content-Type": "application/json"
            },
            json={"value": json.dumps(value)},
            timeout=5
        )
    except:
        pass


# =============== Settings/Cache ===============
def load_settings():
    return kv_get(SETTINGS_KEY, {})


def save_settings(data):
    kv_set(SETTINGS_KEY, data)


def load_cache():
    return kv_get(CACHE_KEY, {})


def save_cache(cache):
    kv_set(CACHE_KEY, cache)


# =============== èªè¨€æ­£è¦åŒ– ===============
LANG_ALIASES = {
    "ä¸­æ–‡": ["ä¸­æ–‡", "ç¹ä¸­", "ç¹é«”ä¸­æ–‡", "zh", "chinese", "cn"],
    "è‹±æ–‡": ["è‹±æ–‡", "è‹±", "en", "english"],
    "è¶Šå—æ–‡": ["è¶Šå—æ–‡", "è¶Šæ–‡", "vi", "vietnamese"],
    "æ—¥æ–‡": ["æ—¥æ–‡", "jp", "ja", "japanese"],
    "éŸ“æ–‡": ["éŸ“æ–‡", "kr", "ko", "korean"],
    "å°å°¼æ–‡": ["å°å°¼æ–‡", "id", "indonesian", "bahasa"],
    "æ³°æ–‡": ["æ³°æ–‡", "th", "thai"],
    "è¥¿ç­ç‰™æ–‡": ["è¥¿ç­ç‰™æ–‡", "è¥¿æ–‡", "es", "spanish"],
    "å¾·æ–‡": ["å¾·æ–‡", "de", "german"],
}


def normalize_lang(name: str) -> str:
    n = name.strip().lower()
    for std, alts in LANG_ALIASES.items():
        if n == std.lower() or n in [a.lower() for a in alts]:
            return std
    return name.strip()


# =============== èªè¨€åµæ¸¬ ===============
def detect_language(text: str, cache):
    cache_key = f"detect::{text}"

    if cache_key in cache:
        return cache[cache_key]

    prompt = (
        "è«‹åˆ¤æ–·ä»¥ä¸‹å¥å­çš„èªè¨€ç¨®é¡ï¼Œåƒ…å›ç­”ï¼šä¸­æ–‡ / è‹±æ–‡ / è¶Šå—æ–‡ / æ—¥æ–‡ / éŸ“æ–‡ / å°å°¼æ–‡ / æ³°æ–‡ / è¥¿ç­ç‰™æ–‡ / å¾·æ–‡ã€‚\n"
        "è‹¥ç„¡æ³•åˆ¤æ–·ï¼Œå›è‹±æ–‡ã€‚\n\n"
        f"å¥å­ï¼š{text}"
    )

    try:
        res = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯èªè¨€è­˜åˆ¥å°ˆå®¶ã€‚"},
                {"role": "user", "content": prompt},
            ],
            temperature=0
        )

        lang = normalize_lang(res.choices[0].message.content.strip())
        cache[cache_key] = lang
        save_cache(cache)
        return lang

    except:
        return "è‹±æ–‡"


# =============== ç¿»è­¯åŠŸèƒ½ ===============
def translate_text(text, source_lang, target_lang, cache, tone="normal"):
    cache_key = f"trans::{source_lang}->{target_lang}::{tone}::{text}"

    if cache_key in cache:
        return cache[cache_key]

    tone_map = {
        "normal": "è‡ªç„¶æµæš¢ã€å£èªåŒ–ä½†ä¿æŒç¦®è²Œã€‚",
        "formal": "æ­£å¼ã€æ›¸é¢åŒ–ã€ç²¾æº–ã€‚",
        "casual": "è¼•é¬†å£èªã€æœ‹å‹èŠå¤©èªæ°£ã€‚",
    }

    style = "è‡ªç„¶æµæš¢çš„ç¹é«”ä¸­æ–‡ï¼ˆå°ç£ç”¨èªï¼‰" if "ä¸­" in target_lang else target_lang

    prompt = (
        f"è«‹å°‡ä»¥ä¸‹å…§å®¹ç¿»è­¯æˆ {style}ï¼Œèªæ°£ï¼š{tone_map[tone]}\n"
        f"è‹¥å·²æ˜¯ç›®æ¨™èªè¨€ï¼Œè«‹ç›´æ¥è¼¸å‡ºåŸæ–‡ã€‚\n\n"
        f"å…§å®¹ï¼š\n{text}"
    )

    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­ç¿»è­¯å“¡ã€‚"},
            {"role": "user", "content": prompt},
        ],
        temperature=0.3
    )

    result = res.choices[0].message.content.strip()

    # ç¹é«”åŒ–ä¿®æ­£
    if "ä¸­" in target_lang:
        trad = {
            "è¿™": "é€™", "ç€": "è‘—", "ä¹ˆ": "éº¼", "ä¸º": "ç‚º", "äº": "æ–¼",
            "è§‰": "è¦º", "å¬": "è½", "å…³": "é—œ", "å¤´": "é ­", "ç”µ": "é›»",
        }
        for k, v in trad.items():
            result = result.replace(k, v)

    cache[cache_key] = result
    save_cache(cache)

    return result


# =============== LINE å›è¦† ===============
def line_reply(reply_token, text):
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}",
    }
    body = {
        "replyToken": reply_token,
        "messages": [{"type": "text", "text": text[:4900]}],
    }
    requests.post(LINE_REPLY_API, headers=headers, json=body)


# =============== webhook ä¸»ç¨‹å¼ ===============
@app.post("/api/webhook")
async def webhook(req: Request):
    try:
        body = await req.json()
    except:
        return {"status": "ok"}

    events = body.get("events", [])

    settings = load_settings()
    cache = load_cache()

    for ev in events:
        if ev.get("type") != "message":
            continue

        msg = ev.get("message", {})
        if msg.get("type") != "text":
            continue

        user_msg = msg.get("text", "").strip()
        msg_lower = user_msg.lower()
        reply_token = ev.get("replyToken")
        user_id = ev.get("source", {}).get("userId")
        key = f"user:{user_id}"

        if key not in settings:
            settings[key] = {
                "enabled": True,
                "target": "ä¸­æ–‡",
                "tone": "normal",
                "smart": False,
            }

        cfg = settings[key]

        # ===== æŒ‡ä»¤å€ =====
        if msg_lower == "/help":
            line_reply(reply_token,
                       "ğŸ“˜ æŒ‡ä»¤æ¸…å–®ï¼š\n/set\n/status\n/on\n/off\n/reset\n/tone\n/smart\n/langlist\n/clearcache")
            continue

        if msg_lower == "/clearcache":
            save_cache({})
            line_reply(reply_token, "ğŸ”„ å¿«å–å·²æ¸…é™¤")
            continue

        if msg_lower == "/langlist":
            line_reply(reply_token, "ğŸŒ æ”¯æ´ï¼šä¸­æ–‡ã€è‹±æ–‡ã€è¶Šå—æ–‡ã€æ—¥æ–‡ã€éŸ“æ–‡ã€å°å°¼æ–‡ã€æ³°æ–‡ã€è¥¿ç­ç‰™æ–‡ã€å¾·æ–‡")
            continue

        if msg_lower.startswith("/tone "):
            t = msg_lower.split(" ", 1)[1]
            if t in ["normal", "formal", "casual"]:
                cfg["tone"] = t
                save_settings(settings)
                line_reply(reply_token, f"ğŸ™ï¸ å·²è¨­å®šèªæ°£ï¼š{t}")
            continue

        if msg_lower == "/smart on":
            cfg["smart"] = True
            save_settings(settings)
            line_reply(reply_token, "ğŸ¤– Smart æ¨¡å¼ ON")
            continue

        if msg_lower == "/smart off":
            cfg["smart"] = False
            save_settings(settings)
            line_reply(reply_token, "ğŸ§© Smart æ¨¡å¼ OFF")
            continue

        if msg_lower.startswith("/set "):
            lang = normalize_lang(msg_lower.replace("/set", "").strip())
            cfg["target"] = lang
            cfg["enabled"] = True
            save_settings(settings)
            line_reply(reply_token, f"âœ… å·²è¨­å®šï¼šç¿»è­¯æˆ {lang}")
            continue

        if msg_lower == "/status":
            line_reply(
                reply_token,
                f"ğŸ”§ è¨­å®šï¼š\nç‹€æ…‹ï¼š{'ON' if cfg['enabled'] else 'OFF'}\nèªè¨€ï¼š{cfg['target']}\nèªæ°£ï¼š{cfg['tone']}\nSmartï¼š{'ON' if cfg['smart'] else 'OFF'}"
            )
            continue

        if msg_lower == "/off":
            cfg["enabled"] = False
            save_settings(settings)
            line_reply(reply_token, "â¸ï¸ ç¿»è­¯ OFF")
            continue

        if msg_lower == "/on":
            cfg["enabled"] = True
            save_settings(settings)
            line_reply(reply_token, "â–¶ï¸ ç¿»è­¯ ON")
            continue

        if msg_lower == "/reset":
            settings[key] = {
                "enabled": True,
                "target": "ä¸­æ–‡",
                "tone": "normal",
                "smart": False,
            }
            save_settings(settings)
            line_reply(reply_token, "â™»ï¸ å·²é‡è¨­ç‚ºä¸­æ–‡")
            continue

        # =============== è‡ªå‹•ç¿»è­¯ ===============
        if cfg["enabled"]:
            detected = detect_language(user_msg, cache)

            target = (
                "è¶Šå—æ–‡" if cfg["smart"] and detected == "ä¸­æ–‡"
                else "ä¸­æ–‡" if cfg["smart"] and detected == "è¶Šå—æ–‡"
                else cfg["target"]
            )

            if detected != target:
                result = translate_text(user_msg, detected, target, cache, tone=cfg["tone"])
                line_reply(reply_token, result)

    return {"status": "ok"}

